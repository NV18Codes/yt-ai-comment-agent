import streamlit as st
from streamlit_lottie import st_lottie
from deep_translator import GoogleTranslator
from langdetect import detect, LangDetectException
import emoji
import re
from transformers import pipeline, set_seed
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import openai
import os
from dotenv import load_dotenv
from youtube_comment_downloader import YoutubeCommentDownloader
from yt_dlp import YoutubeDL
import requests

# Load environment variables
load_dotenv()

# Access the OpenAI API Key from Streamlit secrets
openai.api_key = st.secrets["openai"]["api_key"]

# --- Setup ---
set_seed(42)

# Fix for sentiment analysis (using CPU if GPU is not available)
sentiment_analyzer = pipeline("sentiment-analysis", device=-1)  # -1 for CPU (0 for GPU)

# --- Allowed Languages ---
allowed_languages = ['en', 'hi', 'kn', 'te', 'ta', 'ko', 'ja']

# --- Utilities ---
def load_lottieurl(url):
    try:
        r = requests.get(url)
        if r.status_code != 200:
            return None
        return r.json()
    except Exception as e:
        st.error(f"Error loading Lottie URL: {str(e)}")
        return None

def safe_detect_language(text):
    try:
        if not text or len(text.strip()) < 3:
            return 'en'
        # Check for emoji-only text
        if all(char in emoji.EMOJI_DATA for char in text.strip()):
            return 'emoji'

        # Manually checking for language patterns (for Indian languages like Kannada, Telugu, Tamil)
        indian_keywords = {
            'hi': ['kaise', 'kya', 'aap', 'hai', 'kar', 'ho', 'pyar', 'dost', 'suno'],
            'kn': ['‡≤π‡≥á‡≤ó‡≤ø‡≤¶‡≥Ü', '‡≤®‡≥Ä‡≤µ‡≥Å', '‡≤Ö‡≤µ‡≤®‡≥Å', '‡≤á‡≤¶‡≥Å', '‡≤™‡≥ç‡≤∞‡≥Ä‡≤§‡≤ø'],
            'te': ['‡∞è‡∞Ç‡∞ü‡∞ø', '‡∞®‡±á‡∞®‡±Å', '‡∞Æ‡±Ä‡∞∞‡±Å', '‡∞Ö‡∞¶‡∞ø', '‡∞™‡±ç‡∞∞‡±á‡∞Æ'],
            'ta': ['‡Æé‡Æ™‡Øç‡Æ™‡Æü‡Æø', '‡Æ®‡ØÄ‡Æô‡Øç‡Æï‡Æ≥‡Øç', '‡ÆÖ‡Æ§‡ØÅ', '‡Æï‡Ææ‡Æ§‡Æ≤‡Øç', '‡Æ™‡Øä‡Æ±‡ØÅ‡Æ™‡Øç‡Æ™‡ØÅ'],
            'ko': ['Ïñ¥ÎñªÍ≤å', 'ÎÑà', 'Í∑∏Í≤É', 'ÏÇ¨Îûë'],
            'ja': ['„Å©„ÅÜ', '„ÅÇ„Å™„Åü', '„Åù„Çå', 'ÊÑõ'],
        }

        # Check if the comment contains keywords from any language
        for lang, keywords in indian_keywords.items():
            if any(keyword in text.lower() for keyword in keywords):
                return lang

        # Use langdetect to detect the language
        lang = detect(text)
        if lang in allowed_languages:
            return lang
        return 'en'
    
    except LangDetectException:
        return 'en'

def detect_tone(text):
    if not text:
        return "Neutral"
    text_lower = text.lower().strip()
    if all(char in emoji.EMOJI_DATA for char in text.strip()):
        return "Emoji"
    if re.search(r"\b\d{1,2}:\d{2}\b", text_lower):
        return "Timestamp"
    if re.search(r"\b(19|20)\d{2}\b", text_lower):
        return "Year"

    patterns = {
        "Humor": r"\b(lol|lmao|rofl|haha|funny)\b",
        "Praise": r"\b(love|amazing|great job|thank you|awesome|best)\b",
        "Criticism": r"\b(bad|worst|hate|trash|dislike)\b",
        "Support": r"\b(nice work|keep it up|respect|well done)\b",
        "Confusion": r"\b(confused|what)\b",
        "Request": r"\b(can you|please|would you|could you)\b",
        "Disapproval": r"\b(wtf|cringe|eww)\b",
    }

    for tone, pattern in patterns.items():
        if re.search(pattern, text_lower):
            return tone
    return "Neutral"

def detect_sentiment(text):
    try:
        if not text:
            return "Neutral"
        result = sentiment_analyzer(text)[0]
        return result['label'].capitalize()
    except Exception as e:
        st.error(f"Error during sentiment analysis: {str(e)}")
        return "Neutral"

def translate_to_english(text):
    try:
        if not text:
            return text
        return GoogleTranslator(source='auto', target='en').translate(text)
    except Exception as e:
        st.error(f"Error during translation to English: {str(e)}")
        return text

def translate_back(reply, lang):
    try:
        if lang in allowed_languages and lang != 'en':
            return GoogleTranslator(source='en', target=lang).translate(reply)
        return reply
    except Exception as e:
        st.error(f"Error during translation back: {str(e)}")
        return reply

def generate_reply(comment, model="gpt-4", video_title=""):
    if not comment:
        return "Thanks for your feedback! üëç"
    
    tone = detect_tone(comment)

    if tone == "Emoji":
        return comment
    if tone == "Timestamp":
        return "IKR! üî• That part was epic!"
    if tone == "Year":
        return "Good music days! üé∂ Let's vibe!"

    tone_templates = {
        "Humor": "üòÇ That was funny! Glad you're enjoying it!",
        "Criticism": "Thanks for your feedback. We'll improve! üôè",
        "Praise": "So glad you liked it! üòä",
        "Support": "Appreciate the support! üí™",
        "Confusion": "Sorry if it wasn't clear. Let us know! ü§î",
        "Request": "Thanks for the suggestion! We'll consider it. üôå",
        "Disapproval": "We'll try to do better next time. üí°",
    }

    if tone in tone_templates:
        return tone_templates[tone]

    try:
        prompt = f"""You are a helpful, friendly AI that replies to YouTube comments.
Reply in 1-2 conversational sentences. Include a light emoji if appropriate.

Comment: \"{comment}\"
Reply:"""
        response = openai.ChatCompletion.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=100
        )
        reply = response.choices[0].message['content'].strip()
        return emoji.emojize(reply, language='alias')
    except Exception as e:
        st.error(f"Error generating reply: {str(e)}")
        return "Thanks for your feedback! üëç"

# --- Streamlit App ---
def main():
    st.set_page_config(page_title="YouTube Comment AI Replier", layout="wide", page_icon="ü§ñ")

    col1, col2 = st.columns([2, 1])
    with col1:
        st.markdown("""<h1 style='font-size: 2.7rem;'>ü§ñ YouTube Comment <span style='color:#0059b3;'>AI Replier</span></h1>
            <p style='font-size: 1.2rem;'>‚ú® Craft replies and understand viewer sentiment instantly!</p>
        """, unsafe_allow_html=True)
    with col2:
        lottie = load_lottieurl("https://assets1.lottiefiles.com/packages/lf20_w51pcehl.json")
        if lottie:
            st_lottie(lottie, height=170, key="ai")

    st.sidebar.title("‚öôÔ∏è Configuration")
    model_choice = st.sidebar.selectbox("ü§ñ Model", ["gpt-4"])
    comment_count = st.sidebar.slider("üí¨ Number of Comments", 5, 50, 10)
    show_charts = st.sidebar.checkbox("üìä Show Charts", value=True)

    url = st.text_input("üìΩÔ∏è YouTube Video URL or ID")
    sort_by = st.selectbox("üîΩ Sort Results By", ["Original", "Tone", "Sentiment"])

    if st.button("‚ú® Generate Replies") and url:
        try:
            st.info("Fetching video info and comments...")
            ydl_opts = {"quiet": True}
            with YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(url, download=False)
                video_title = info.get("title") or "Untitled"

            downloader = YoutubeCommentDownloader()
            comments = [c['text'] for _, c in zip(range(comment_count), downloader.get_comments_from_url(url))]

            replies, tones, sentiments, langs = [], [], [], []

            with st.spinner("Generating replies..."):
                for c in comments:
                    lang = safe_detect_language(c)
                    langs.append(lang)

                    if lang in ['en', 'emoji']:
                        eng_comment = c
                    else:
                        eng_comment = translate_to_english(c)

                    tone = detect_tone(eng_comment)
                    sentiment = detect_sentiment(eng_comment)
                    reply = generate_reply(eng_comment, model=model_choice, video_title=video_title)

                    final_reply = translate_back(reply, lang)
                    replies.append(final_reply)
                    tones.append(tone)
                    sentiments.append(sentiment)

            # Here we maintain the original order
            df = pd.DataFrame({
                "Comment": comments,
                "Reply": replies,
                "Tone": tones,
                "Sentiment": sentiments,
                "Lang": langs
            })

            if sort_by != "Original":
                df = df.sort_values(by=sort_by)

            st.subheader("üí¨ AI Replies")
            st.dataframe(df)

            st.download_button("üì• Download CSV", df.to_csv(index=False), "youtube_replies.csv", "text/csv")

            if show_charts:
                st.subheader("üìä Insights")
                fig1, ax1 = plt.subplots()
                sns.countplot(data=df, x="Sentiment", ax=ax1, palette="viridis")
                ax1.set_title("Sentiment Distribution")
                st.pyplot(fig1)

                fig2, ax2 = plt.subplots()
                sns.countplot(data=df, x="Tone", ax=ax2, palette="coolwarm")
                ax2.set_title("Tone Breakdown")
                st.pyplot(fig2)

        except Exception as e:
            st.error(f"‚ùå Error: {str(e)}")

if __name__ == "__main__":
    main()
